{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment\n",
    "- Sentiment detection ist bei Texten ein relativ altes Thema\n",
    "- Seit Deep Learning sind die \"alten\" Methoden abgeschlagen\n",
    "- Allerdings ist es nicht ganz trivial einen eigenen Classifier für Deep Learning zu schreiben \n",
    "- Wenn ihr est trotzdem mal probieren wollt, dann findet ihr eine Anleitung in meinem Blog Post:\n",
    "    - https://www.liip.ch/en/blog/sentiment-detection-with-keras-word-embeddings-and-lstm-deep-learning-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/plotti/miniconda3/envs/nlp/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/plotti/miniconda3/envs/nlp/lib/python3.8/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in /Users/plotti/miniconda3/envs/nlp/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: joblib in /Users/plotti/miniconda3/envs/nlp/lib/python3.8/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: click in /Users/plotti/miniconda3/envs/nlp/lib/python3.8/site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/plotti/miniconda3/envs/nlp/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2022.7.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob_de import TextBlobDE\n",
    "#from textblob import TexBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextBlobDE(u\"Das Auto ist sehr schön!\").sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-1.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlobDE(u\"Das ist ein hässliches Auto.\")     \n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-1.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlobDE(u\"Ich bin furchtbar sauer!\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlobDE(u\"Das ist ein neutraler Satz.\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment mit Spacy und SentiWS\n",
    "- https://github.com/Liebeck/spacy-sentiws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: /Users/plotti/Library/Python/3.7/bin/pip: bad interpreter: /usr/local/opt/python/bin/python3.7: no such file or directory\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: spacy-sentiws in /usr/local/lib/python3.8/site-packages (0.0.6)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy-sentiws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import spacy_fastlang\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "nlp.add_pipe(\"language_detector\")\n",
    "doc = nlp('Life is like a box of chocolates. You never know what you are gonna get.')\n",
    "doc._.language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy_sentiws.spaCySentiWS object at 0x7fc41ebe0910> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mde_core_news_sm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m sentiws \u001b[38;5;241m=\u001b[39m spaCySentiWS(sentiws_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiws\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentiws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDie Dummheit der Unterwerfung blüht in hübschen Farben.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/site-packages/spacy/language.py:779\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    777\u001b[0m     bad_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(factory_name)\n\u001b[1;32m    778\u001b[0m     err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE966\u001b[38;5;241m.\u001b[39mformat(component\u001b[38;5;241m=\u001b[39mbad_val, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    780\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m factory_name\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names:\n",
      "\u001b[0;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy_sentiws.spaCySentiWS object at 0x7fc41ebe0910> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy_sentiws import spaCySentiWS\n",
    "\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "sentiws = spaCySentiWS(sentiws_path='sentiws')\n",
    "nlp.add_pipe(sentiws)\n",
    "doc = nlp('Die Dummheit der Unterwerfung blüht in hübschen Farben.')\n",
    "\n",
    "for token in doc:\n",
    "    print('{}, {}, {}'.format(token.text, token._.sentiws, token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spracherkennung\n",
    "- wiederum ein einfaches Thema wird z.B. von TextblobDE unterstützt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlobDE(u\"Ich gehe ins Schwimmbad\").detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlobDE(u\"Ide plywac\").detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlobDE(u\"I am going to the swimming pool\").detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlobDE(\"Eu vou ao trem\").detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy-language-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_language_detection.spacy_language_detector.LanguageDetector at 0x7ff47faf9790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_language_detection import LanguageDetector\n",
    "\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector(seed=42)  # We use the seed 42\n",
    "\n",
    "\n",
    "nlp_model = spacy.load(\"de_core_news_sm\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp_model.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'de', 'score': 0.999997643801233}\n"
     ]
    }
   ],
   "source": [
    "# Document level language detection\n",
    "text = \"Ich bin ein berliner\"\n",
    "doc = nlp_model(text)\n",
    "language = doc._.language\n",
    "print(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spellchecking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Geht aktuell leider nur auf englisch. \n",
    "- Damit könnt ihr zumindest Eure englisch sprachigen Kollegen kontrollieren.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Writing easy sentences in english is easy but the do have to be correct.\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(u'Writing easy sentences in english is easy but thei do hafe to be korrekt.')\n",
    "blob.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.8818927138890114),\n",
       " ('they', 0.043394895755278357),\n",
       " ('their', 0.03256270110636047),\n",
       " ('them', 0.024694759113148498),\n",
       " ('then', 0.01716842244457178),\n",
       " ('thee', 0.0002865076916295676)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[8].spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
